{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamjain02/Deep-Learning-Projects/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjIwQLgq5AZP",
        "colab_type": "text"
      },
      "source": [
        "# **Cat v/s Dog Classification**\n",
        "---\n",
        "**Problem Statement :** This is the very basic problem of classification of Images of two categories using the Deep Neural Networks.\n",
        "\n",
        "Image classification is the process of taking an input (like a picture) and outputting a class (like “cat”) or a probability that the input is a particular class (“there’s a 90% probability that this input is a cat”).\n",
        "\n",
        "The Dataset can be found easily on Kaggle or any other website. This dataset consists of 4000 Images each of Cat and Dog in the Training Set and 1000 Images each of Cat and Dog in the Test Set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk4OXd0u9cWq",
        "colab_type": "text"
      },
      "source": [
        "Image Classification can be solved with the help of a Convolutional Neural Network, CNN. A CNN usually have:\n",
        "\n",
        "1. Convolutional Layers\n",
        "2. ReLU Layers\n",
        "3. Pooling Layers\n",
        "4. Fully connected Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Emp4V967i2",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Uploading Dataset and Unzipping the Files\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYqMg0OeLThm",
        "colab_type": "code",
        "outputId": "cc1bef86-0dc6-4c6a-dc92-603f55c9632a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsLtEXMhH7lZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unzipping the Files\n",
        "from zipfile import ZipFile\n",
        "file_name='/content/drive/My Drive/P16-Convolutional-Neural-Networks.zip'\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLlDSVH07IEb",
        "colab_type": "text"
      },
      "source": [
        "##**Steps of Solution :**\n",
        "\n",
        "1. Importing the required Libraries\n",
        "2. Image Augmentation\n",
        "3. Building the CNN Models.\n",
        "4. Fitting the CNN Models to the Images and finding their Accuracies.\n",
        "5. Saving the Best Model.\n",
        "6. Making Sample Predictions.\n",
        "\n",
        "\n",
        "\n",
        "> **Note :** This problem of Image Classification has no traditional **\"X\"** & **\"y\"** variables although the solution of the problem is a **supervised learning technique**. Here input X is the image itself and output y is the label \"Cat\" or \"Dog\". \n",
        "\n",
        "*   If the Dataset is already labeled and segregated as follows, then we can proceed to the solution directly.\n",
        "\n",
        "```\n",
        "dataset_dogs_vs_cats\n",
        "  ── test\n",
        "      ── cats    \n",
        "      ── dogs\n",
        "  ── train\n",
        "      ── cats\n",
        "      ── dogs\n",
        "```\n",
        "*   If the Dataset has just two folders, 'Train' and 'Test', each containing unlabeled images of cats and dogs, we first need to organise the data as the previous case. This can be simply done using the Keras Library.     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7b1VIw37aCC",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Step 1. Importing the Libraries\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVgRgesC6saS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential # To initialise the Neural Network\n",
        "from keras.layers import Convolution2D # To add Convolutional Layers\n",
        "from keras.layers import MaxPooling2D # For Pooling Step\n",
        "from keras.layers import Flatten # For converting Pooled features to Matrix\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRr6UP_M5A6X",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Step 2. Image Augmentation\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0wUPiveUWNw",
        "colab_type": "text"
      },
      "source": [
        "To train a CNN model more accurately on the image dataset, we can either increase the number of images in the dataset or apply **Image Augmentation**.\n",
        "\n",
        "Image augmentation will create many batches of our images, and in each batch it will apply some random transformation on a random selection of the images, like rotation them, flipping them etc. ; and eventually we will get a large diversification in the batches, and therefore a lot of material to train.\n",
        "\n",
        "It can also act as a regularization technique, adding noise to the training data, and encouraging the model to learn the same features, invariant to their position in the input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNcS3WPu8Y9K",
        "colab_type": "text"
      },
      "source": [
        "**ImageDataGenerator** is used to scale the images (similar to feature scaling in ML). It is scaled by 255 because the values of pixels range from 0-255 for 8-bit data. \n",
        "\n",
        "**flow_from_directory** is used to convert all the images into same size of (64x64), and using batch size of 32 means the weights of neural network will be updated after traing on each batch of 32 images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QFUy2PcDPaZ",
        "colab_type": "code",
        "outputId": "170830e2-6968-4329-9df2-8af9b975c2e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "training_set = train_datagen.flow_from_directory('/content/Convolutional_Neural_Networks/dataset/training_set', target_size = (64, 64), batch_size = 32, class_mode = 'binary')\n",
        "test_set = test_datagen.flow_from_directory('/content/Convolutional_Neural_Networks/dataset/test_set', target_size = (64, 64), batch_size = 32, class_mode = 'binary')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXpCwc-oBRlO",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Step 3. Building the CNN Models\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5717X-Un-scP",
        "colab_type": "text"
      },
      "source": [
        "A CNN Model\n",
        "*   starts with an input image\n",
        "*   **Convolution Layer:** applies many different filters to it to create a feature map and applies a ReLU function to increase non-linearity.\n",
        "*   **Pooling Layer:** applies a pooling layer to each feature map.\n",
        "    \n",
        "    > The size of Pooling Layer is usually taken as 2x2 to avoid loosing features of the feature map. \n",
        "*   **Flattening Layer:** flattens the pooled images into one long vector.\n",
        "*   **Fully Connected Layer:** inputs the vector into a fully connected artificial neural network.\n",
        "*   processes the features through the network. The final fully connected layer provides the “voting” of the classes that we’re after.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5OdteM9DxCj",
        "colab_type": "text"
      },
      "source": [
        "    A CNN model may have many number of Convolutional Layers. Standard Procedure involves taking 32, (3x3) filters. \n",
        "\n",
        "The number of filters are increased as the number of Convolutional layers are increased."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1j6P2C0G4eN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Single Convolution Layer CNN Model\n",
        "def cnn_model1():\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation = 'relu'))\n",
        "  classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  classifier.add(Flatten())\n",
        "  classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "  classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "  # Compiling the CNN\n",
        "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  return classifier\n",
        "\n",
        "# Two Convolution Layer CNN Model\n",
        "def cnn_model2():\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation = 'relu'))\n",
        "  classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  classifier.add(Convolution2D(64, 3, 3, input_shape=(64, 64, 3), activation = 'relu'))\n",
        "  classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  classifier.add(Flatten())\n",
        "  classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "  classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "  # Compiling the CNN\n",
        "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  return classifier\n",
        "\n",
        "# Three Convolution Layer CNN Model\n",
        "def cnn_model3():\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation = 'relu'))\n",
        "  classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  classifier.add(Convolution2D(64, 3, 3, input_shape=(64, 64, 3), activation = 'relu'))\n",
        "  classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  classifier.add(Convolution2D(128, 3, 3, input_shape=(64, 64, 3), activation = 'relu'))\n",
        "  classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  classifier.add(Flatten())\n",
        "  classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "  classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "  # Compiling the CNN\n",
        "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OmigMYV5a0O",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Step 4. Fitting the CNN Models to the Images and finding their Accuracies.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arRy-ZG4Dp7R",
        "colab_type": "text"
      },
      "source": [
        "A CNN trains through forward propagation and backpropagation for many, many epochs. This repeats until we have a well-defined neural network with trained weights and feature detectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB-eCOgNLyfr",
        "colab_type": "code",
        "outputId": "b64c840c-811b-47c3-a17e-1e6d0a7aa8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Fitting the CNN Model_1 to the images\n",
        "model1 = cnn_model1()\n",
        "accuracies1 = np.array(model1.fit_generator(training_set, steps_per_epoch = 8000, epochs = 2, validation_data = test_set, validation_steps = 2000))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "8000/8000 [==============================] - 1037s 130ms/step - loss: 0.4563 - acc: 0.7798 - val_loss: 0.5500 - val_acc: 0.7665\n",
            "Epoch 2/2\n",
            "8000/8000 [==============================] - 1050s 131ms/step - loss: 0.2915 - acc: 0.8740 - val_loss: 0.7769 - val_acc: 0.7510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM0mRZdf2R1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "5cbbcb67-5a47-40cc-af02-8ce9c2e1d810"
      },
      "source": [
        "accuracy1 = np.mean(accuracies1.history['val_acc'])\n",
        "variance1 = np.std(accuracies1.history['val_acc'])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-ef346f84fc2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvariance1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'history'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp-ZFpUrcqWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ff7ae9a3-1746-495d-9ba3-c139dab8039a"
      },
      "source": [
        "# Fitting the CNN Model_2 to the images\n",
        "model2 = cnn_model2()\n",
        "accuracies2 = model2.fit_generator(training_set, steps_per_epoch = 8000, epochs = 2, validation_data = test_set, validation_steps = 2000)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "8000/8000 [==============================] - 1041s 130ms/step - loss: 0.3485 - acc: 0.8373 - val_loss: 0.6878 - val_acc: 0.7876\n",
            "Epoch 2/2\n",
            "8000/8000 [==============================] - 996s 124ms/step - loss: 0.0895 - acc: 0.9669 - val_loss: 1.0318 - val_acc: 0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAKyqV8d2nhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy2 = np.mean(accuracies2.history['val_acc'])\n",
        "variance2 = np.std(accuracies2.history['val_acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLfFTQSGcq8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6a0b3059-65fd-465e-e096-fb7f25f3da78"
      },
      "source": [
        "# Fitting the CNN Model_3 to the images\n",
        "model3 = cnn_model3()\n",
        "accuracies3 = model3.fit_generator(training_set, steps_per_epoch = 8000, epochs = 2, validation_data = test_set, validation_steps = 2000)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "8000/8000 [==============================] - 1006s 126ms/step - loss: 0.3282 - acc: 0.8453 - val_loss: 0.5719 - val_acc: 0.8121\n",
            "Epoch 2/2\n",
            "8000/8000 [==============================] - 1027s 128ms/step - loss: 0.0941 - acc: 0.9641 - val_loss: 0.6548 - val_acc: 0.8457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZEDZggd2y2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy3 = np.mean(accuracies3.history['val_acc'])\n",
        "variance3 = np.std(accuracies3.history['val_acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqNIlDEUe_Kb",
        "colab_type": "text"
      },
      "source": [
        "> **Comparison of Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZMcoNmpe9YW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5eb26c02-6bb1-47ec-d413-89bfbad385dc"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Name: CNN with-', '1 Convolution Layer', '2 Convolution Layer', '3 Convolution Layer'])\n",
        "t.add_row(['Accuracy', accuracy1, accuracy2, accuracy3])\n",
        "t.add_row(['variance', variance1, variance2, variance3])\n",
        "print(t)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+----------------------+----------------------+---------------------+\n",
            "| Name: CNN with- | 1 Convolution Layer  | 2 Convolution Layer  | 3 Convolution Layer |\n",
            "+-----------------+----------------------+----------------------+---------------------+\n",
            "|     Accuracy    |  0.7201931150293871  |  0.7938066945014639  |  0.8288811019619542 |\n",
            "|     variance    | 0.030590843035341226 | 0.006234258119503788 | 0.01680627202998136 |\n",
            "+-----------------+----------------------+----------------------+---------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O49f7NzQ5tj0",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Step 5. Saving the Best Model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmJ120kJbBlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump(model3, open('model.pkl','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRBEYwFh51ca",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Step 6. Making Sample Predictions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73dRbnY6MJ4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/Convolutional_Neural_Networks/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "actual_test_image = test_image\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model3.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxVtt1AIOtN_",
        "colab_type": "code",
        "outputId": "00481873-8226-4d51-c5ee-2c3b081cdc57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "# Viewing the Actual Test Image\n",
        "print(\"The actual image is :-\")\n",
        "actual_test_image"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The actual image is :-\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAjZ0lEQVR4nD26abSm11Xnt4dznvEd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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F6FF8831FD0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWeUF0xJOv6l",
        "colab_type": "code",
        "outputId": "ae8e4b21-8673-4f37-f4c6-7468949898e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Viewing the Prediction\n",
        "print(\"The predicted image is a\", prediction)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted image is a dog\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}