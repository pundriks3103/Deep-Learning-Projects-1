{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classification_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M96RkmP1AH-T",
        "colab_type": "text"
      },
      "source": [
        "### **Mounting Google Drive to upload Datasets**\n",
        "___\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MWQUbKjARvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRuwwE5_Adc8",
        "colab_type": "text"
      },
      "source": [
        "### **Importing the required libraries**\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIyz0RzFAT1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.text import one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XajmwehKBH7g",
        "colab_type": "text"
      },
      "source": [
        "### **Loading the Dataset**\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN_9BCy5BDdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Mylo/train.csv\", encoding = 'unicode_escape')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X8EGbc5BQkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop('post_id', axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv2nsma8BRDa",
        "colab_type": "code",
        "outputId": "994b8e1b-dd8a-48f5-b4da-188e4002d6b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>user_stage</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alhamdulilh,  blessed with beautiful baby girl...</td>\n",
              "      <td>pregnant</td>\n",
              "      <td>Announcements&amp;Celebrations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Breastfeeding mother ko chai pini chaiye usse ...</td>\n",
              "      <td>mother</td>\n",
              "      <td>General Baby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hii all as I am preganent with twins on coming...</td>\n",
              "      <td>pregnant</td>\n",
              "      <td>General Pregnancy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mujhy mild cramp sa feeling Hai lower main aur...</td>\n",
              "      <td>pregnant</td>\n",
              "      <td>General Pregnancy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can I drink lion dates syrup</td>\n",
              "      <td>pregnant</td>\n",
              "      <td>Diet&amp;Nutrition</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  ...                         tag\n",
              "0  Alhamdulilh,  blessed with beautiful baby girl...  ...  Announcements&Celebrations\n",
              "1  Breastfeeding mother ko chai pini chaiye usse ...  ...                General Baby\n",
              "2  Hii all as I am preganent with twins on coming...  ...           General Pregnancy\n",
              "3  Mujhy mild cramp sa feeling Hai lower main aur...  ...           General Pregnancy\n",
              "4                       Can I drink lion dates syrup  ...              Diet&Nutrition\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDCp5aVcBd2R",
        "colab_type": "text"
      },
      "source": [
        "### **Creating input and output feature Columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4XPDZxNBVS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = df.iloc[:,0].values\n",
        "y = df.iloc[:,2].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slgnT9mEBp2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelencoder = LabelEncoder()\n",
        "onehotencoder = OneHotEncoder()\n",
        "y = labelencoder.fit_transform(y)\n",
        "y = y.reshape(-1,1)\n",
        "y = onehotencoder.fit_transform(y).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIS9PICZBzlM",
        "colab_type": "text"
      },
      "source": [
        "**Using Word Embedding Method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyeEA_HxBs7c",
        "colab_type": "code",
        "outputId": "09f1135f-e908-4f95-f6a8-ff9c3bb97447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "all_words = []\n",
        "for sent in corpus:\n",
        "    tokenize_word = word_tokenize(sent)\n",
        "    for word in tokenize_word:\n",
        "        all_words.append(word)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syLA6N4gB7kY",
        "colab_type": "code",
        "outputId": "3ceea76d-8c81-4b9f-c6b3-25d96cd8700b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "unique_words = set(all_words)\n",
        "print(len(unique_words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_g1r8mEB-D5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_length = len(unique_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBO5IDgJCB8r",
        "colab_type": "code",
        "outputId": "7e11079d-f8a6-4487-cfda-05b16a923caa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "embedded_sentences = [one_hot(sent, vocab_length) for sent in corpus]\n",
        "print(embedded_sentences )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[192, 433, 671, 646, 198, 501, 267], [1175, 1049, 4, 806, 248, 871, 843, 1197, 4, 877, 773], [1098, 625, 499, 756, 906, 822, 671, 972, 264, 785, 107, 456, 167, 454, 58, 574, 1145, 772, 870, 499, 263, 177, 705, 471, 574, 1039, 797, 371, 345, 574, 1145, 648, 499, 756, 1154, 219, 736, 582, 245, 175, 1065, 794, 116, 797, 1094, 882, 648, 167, 657, 1189, 278, 1175, 166, 574, 706, 736, 262, 278, 454, 58, 574, 706, 1024, 938, 1075, 538, 720, 54, 454, 398, 198, 1092, 1096, 643, 574, 805, 966, 948, 206, 756, 1199, 54, 197, 906, 16], [894, 729, 665, 857, 703, 774, 1194, 111, 1191, 614, 459, 165, 757, 813, 572, 46, 464, 564, 1070, 614, 95, 703, 459, 996, 167, 167, 837, 22, 986, 774], [622, 756, 84, 771, 667, 387], [266, 622, 6, 741, 1088, 463, 1130, 38, 756, 906, 831, 574, 1173, 279, 463, 885, 1130, 581, 221, 868, 398], [622, 756, 977, 77, 192], [756, 906, 264, 34, 1075, 299, 876, 46, 506, 265, 877, 299, 1017, 705, 574, 877, 284, 797, 962, 582, 794, 754, 930, 664, 611, 206], [756, 58, 1047, 1100, 1049, 794, 198, 514, 797, 1089, 880, 206, 756, 977, 498, 252, 514, 1180, 558], [498, 1044, 667, 4, 1214, 584, 814, 408, 63, 39, 197, 95, 305, 359, 1209, 314, 988, 3, 191, 198, 585, 461, 774, 363, 907, 1209, 39, 4, 862, 868, 1061, 4, 585, 165, 654, 988, 213, 561, 774, 359, 574, 677, 224, 103, 363, 459, 579, 407, 1005, 227, 906, 572, 456, 584, 567, 574, 103, 103, 918, 213, 334, 198, 597, 1214, 584, 654, 459, 292, 140, 774, 359, 574, 970, 970, 215, 198, 95, 550, 48, 1207, 1043, 574, 137, 288, 558, 431], [821, 926, 177, 326, 299, 46, 582, 1130, 794, 633, 936, 299, 1050, 574, 794, 686, 299, 296, 299, 756, 714, 786, 797, 664, 279], [1159, 816, 4, 640, 805, 768, 774, 1013, 164, 695, 288, 948, 202, 1149, 58, 288, 459, 539, 768, 299, 363, 564, 58, 288, 1149, 58, 539, 916, 299, 54, 206, 44, 738, 58], [1145, 454, 972, 468, 1130, 1211, 1045, 756, 165, 400, 756, 1154, 1089, 1211, 206], [622, 756, 977, 739], [1147, 1130, 973, 325, 305, 797, 371, 379, 574, 1015, 1204, 84, 664, 1123], [622, 756, 977, 681], [1212, 139, 98, 454, 359, 578, 930, 198, 501, 868, 198, 1143, 1101, 407, 578, 690, 868, 245], [326, 1212, 880, 1145, 337, 957, 1183, 4, 1213, 542, 1055, 116, 479, 1213, 622, 505, 727, 545, 337, 22, 736, 895, 1130, 1183, 606], [68, 505, 96, 870, 572, 868, 619, 1130, 945, 410, 98, 678, 198, 948, 756, 574, 1169, 948, 248, 181, 980, 371, 611, 197], [300, 300, 1045, 1118, 256, 299, 252, 302, 48, 299, 216, 205, 797, 689, 197, 73, 515, 442, 567, 222, 797, 167, 591, 243], [198, 4, 695, 77, 162, 279, 706, 299, 44, 284, 359, 928, 379], [462, 707, 621, 1010, 480, 326, 1090, 1177, 304, 720, 999, 331, 699, 198, 4, 1034, 278, 86, 44, 1009, 1023, 966, 817, 197], [499, 613, 774, 132, 309, 138, 827, 347, 326, 561, 774, 1036, 851, 165, 680, 165, 461, 774], [1170, 1145, 756, 165, 636, 126, 464, 1023, 597, 906, 387, 591, 989, 200, 274, 274, 792, 326, 1063, 610], [622, 756, 977, 680, 344, 1163, 395, 1163, 1130, 496], [407, 73, 1026, 325, 337, 1173, 143, 1130, 1022, 651, 574, 820, 948, 300, 401, 628, 974, 756, 165, 582, 628, 1022, 1183, 797, 664, 129], [1208, 107, 1170, 731, 6, 554, 1059, 736, 830, 1101, 539, 948, 548, 840, 545, 756, 267, 264, 49, 234, 325, 539, 371, 1042, 375, 301, 132, 653, 1070, 1183, 611, 1145, 1065], [756, 1171, 678, 766, 325, 496, 547, 299, 988, 1112, 1065, 756, 741, 758, 554, 547, 545, 1000, 756, 741, 988, 1112], [198, 514, 574, 361, 1207], [756, 461, 488, 786, 624, 574, 278, 63, 545, 278, 893, 1107, 325, 1189, 1154, 980, 26, 624, 797, 284, 736, 600, 1130, 407, 633], [73, 619, 615, 797, 407, 118, 449, 325, 664, 132], [1140, 293, 699, 337, 625, 705, 510, 574, 73, 1026, 325, 337, 268, 358, 317, 705, 202, 1130, 167, 605, 248, 678, 101, 517, 671, 794, 1101, 199, 1132, 53, 774, 25, 703, 4, 828, 1133, 6, 433, 95, 1189, 1095, 555, 445, 99, 1195, 757, 363, 780, 677, 504, 774], [622, 6, 1145, 163, 454, 14, 285, 214, 664, 582], [1098, 794, 595, 476, 27, 823, 1037, 582, 515, 825, 264, 1065, 756, 865, 496, 178, 707, 371, 1081, 1172, 600, 299, 756, 865, 574, 889, 371, 1081, 22, 600, 880, 797, 407, 125, 496, 197, 359, 773], [1204, 132, 1083, 786, 93, 597, 1165, 830, 191, 591, 1004], [1052, 671, 198, 501, 225, 772, 870, 264, 667, 1037, 173, 27, 919, 763, 1136, 198, 27, 219, 774, 370, 554, 690, 1101, 163, 257], [103, 421, 688, 665, 558, 510, 275, 797, 371, 279], [1140, 225, 756, 1018, 794, 590, 496, 214, 1121, 177, 1043, 1011, 103, 469, 407, 1045, 216, 870, 70, 774, 763, 191, 658, 103, 966, 558, 887, 379, 768, 181, 191, 593, 191, 851, 584, 776, 595, 1060, 288, 216, 739, 1060, 590, 156, 4, 999, 1065, 654, 928, 191, 1095, 1092, 774, 44, 442, 793, 326, 181, 191, 651, 116, 479, 181, 39, 502, 1088, 1023, 1043, 1191, 823, 344, 1020, 334, 290, 674, 498, 774, 1158, 790, 1083, 397, 479, 496, 502, 58, 506, 748], [1052, 671, 1197, 1158, 832, 225, 772, 949, 1124, 337, 1183, 605, 299, 794, 574, 809], [1140, 225, 1183, 132, 197, 521, 1183, 768, 299, 398, 191, 574, 529, 558, 510, 299, 496, 206], [797, 345, 406, 279, 84, 822, 69, 496, 43, 574, 1024, 1025, 1130, 678, 889, 678, 690, 664, 70], [398, 1151, 597, 566, 163, 642, 774, 259, 633, 265, 379, 414, 654, 543, 1214, 495, 44, 1006, 1045, 111, 1190, 906, 591, 279, 294], [565, 1070, 177, 496, 1101, 79, 325, 237, 70, 756, 906, 46, 690, 147, 299, 1178, 128, 299, 779, 365, 219, 428, 574, 977, 736, 804, 947, 325, 436, 56, 167, 713, 983, 1071, 678, 889, 238, 46, 407, 663, 648, 756, 167, 53, 1101, 309, 93, 177, 1065, 175, 565, 654, 1189, 771, 53, 371, 1020, 794, 867, 229, 496, 1094, 35, 457, 454, 264, 371], [654, 1214, 774, 95, 398, 1101, 944, 1039, 177, 275, 1065, 363, 41, 582, 500, 1191, 974, 134, 1108, 177, 275, 162, 1159, 945, 496, 774, 359, 640, 896, 697, 1191, 883, 359, 667, 379, 217, 1159, 851, 744, 494, 1191, 1083, 584, 774, 654, 15, 288, 118, 774, 95, 363, 612], [1165, 1212, 926, 439, 4, 595, 205, 469, 407, 1083, 654, 377, 599, 774, 95, 1106, 77, 496, 299], [410, 442, 308, 95, 942, 95, 561, 738, 1065, 534, 845, 299, 868, 299, 1056, 362, 58, 1191, 288, 1065, 1053, 430, 371, 797, 1154, 928, 390, 703, 767, 325, 625, 630, 690, 1189, 6, 268, 375, 889], [797, 371, 516, 574, 741, 497, 930, 970, 574, 741, 957], [622, 83, 454, 678, 902, 14, 325, 414, 299, 1124], [326, 810, 693, 1183, 132, 1000, 505, 1165, 1125, 160, 930, 739, 93, 90, 1130, 407, 849, 558, 514, 337, 1000, 505, 831, 574, 660, 407, 132, 499, 851, 499, 407, 160, 797, 814, 1124, 337, 930, 172, 374, 76, 1170, 1183], [435, 703, 398, 198, 259, 326, 167, 813, 634, 275, 299, 835, 793, 82, 345, 196, 713, 387, 314, 196, 1033, 95, 299, 334, 843, 1023, 44, 162, 1083, 145, 299], [794, 198, 410, 539, 634, 668, 943, 622, 756, 622, 961, 274, 325, 794, 339, 611, 454, 14, 872], [664, 132, 797, 219, 212, 534, 545, 756, 581, 664, 132, 132, 797, 650, 1065, 1039, 229], [496, 454, 678, 14, 930, 198, 501, 1130, 443], [216, 936, 543, 93, 77, 379, 558, 1210, 299, 398, 300, 4, 1195, 197, 1185, 279], [794, 198, 797, 93, 860, 316, 515, 165, 299, 278, 797, 690, 1101, 645, 707, 752, 764, 387, 313, 756, 58, 736, 1101, 595, 715, 515, 1065, 968, 534, 198, 797, 794, 625, 582, 880, 622, 756, 1145], [398, 635, 148, 122, 925, 774, 948, 428, 9, 558, 757, 774, 44, 992, 359, 658, 461, 774], [671, 1111, 1029, 1052, 671, 198, 501, 264, 926, 1037, 618, 1065, 225, 772, 949], [821, 709, 574, 786, 535, 794, 198, 866, 574, 372, 558, 695, 461, 928, 720, 1153, 325, 786, 425, 756, 767, 1011, 613, 496, 1059, 14, 394, 574, 332, 671, 801], [906, 1175, 1049, 622, 756, 1044, 1109, 85, 264, 794, 268, 797, 371, 181, 574, 1044], [1140, 756, 906, 1130, 550, 177, 325, 794, 496, 1101, 961, 515, 756, 906, 703, 1147, 383, 128, 1130, 1194, 1117, 299, 823, 407, 633, 936, 797, 371, 279, 611, 1070, 359], [1140, 225, 654, 25, 605, 191, 1103, 1034, 78, 117, 359, 654, 738, 739, 597, 1043, 299, 654, 759, 359, 946, 600, 299, 379, 398, 497, 946, 326, 752, 717, 299, 327, 288, 1008, 326, 299, 442, 150, 597, 1097, 519, 803, 697, 899, 181, 191, 1045, 417, 519, 1159, 327, 857], [773, 216, 259, 444, 774, 298, 1165, 1159, 475, 39, 944, 136, 290, 919, 550, 4, 43, 936, 558, 187, 275, 538, 37, 936, 597, 300, 774, 813, 363, 326, 222, 1043, 204, 78, 731, 899, 222, 1101, 444, 715, 77, 668, 222, 227, 813, 1101, 1104, 843, 1079, 574, 538, 336, 534, 558, 1210, 290, 202, 312, 564, 1135, 290, 813, 173, 776, 202, 550, 288, 202, 312, 564, 1135, 290, 227, 813, 363, 414, 734, 986, 1043, 288, 199, 704, 564, 290, 813, 288, 363, 193, 222, 95, 363, 660, 1039, 426, 574, 814, 256, 597, 1207, 905, 720, 1004, 290, 813, 363, 414, 34, 407, 574, 288, 363, 919, 468, 678, 564, 1004, 290, 310, 851, 288, 813, 335, 597, 676, 461, 574, 288, 202, 312, 177, 783, 946, 65, 290, 1159, 475, 946, 455, 774, 379, 202, 312, 252, 1083, 1165, 645, 379, 202, 1101, 189, 1083, 621, 564, 774], [622, 756, 910, 928, 545, 845, 1147, 506, 974, 935, 325, 417, 68, 76, 928, 545, 527, 736, 600, 574, 794, 496], [301, 173, 264, 643, 302, 388, 172, 689], [1052, 671, 198, 1154, 264, 1089, 1037, 127, 574, 625, 293, 317, 1154, 414, 359, 299, 226, 359, 1130, 794, 496, 852], [756, 833, 534, 794, 205, 1189], [73, 574, 843, 1209, 877, 930, 258, 496, 1001, 154, 443, 182, 531, 76, 163, 434, 1209, 663, 496, 1162, 25, 1173, 182, 25, 367, 662, 25, 243, 518], [622, 756, 706, 363, 640, 821, 308, 671, 436], [599, 221, 373, 325, 678, 461, 1004, 538], [314, 359, 1003, 621, 500, 597, 284, 1207, 294, 697, 496, 1068], [278, 797, 510, 832, 1209, 715, 574, 1123, 1025, 880, 574, 1145], [756, 166, 574, 109, 794, 641], [794, 198, 797, 325, 1024, 299, 461, 860, 313, 198, 1112, 797, 767, 930, 988, 1130, 823, 299, 313, 108, 797, 767], [1023, 597, 696, 1106, 860, 191, 334, 230, 774, 654, 1111, 162, 334, 790, 774], [1004, 394, 962, 1010, 731, 1107, 299], [331, 733, 534, 134, 772, 949, 278, 461, 774, 398, 181, 39, 772, 949, 949, 621, 768, 1126, 774], [794, 727, 797, 167, 584, 1101, 101, 198, 883, 129, 1050, 670, 582, 906, 721, 499, 596, 794, 167, 989, 1145, 794, 272, 651, 325, 664, 900, 1065, 658, 461, 299, 44, 464, 584, 703, 186, 84, 815, 1034, 14, 906, 84, 294], [410, 857, 518, 19, 736, 59, 739, 371, 705, 407, 964, 551, 606], [44, 1183, 288, 204, 240, 968, 962, 191, 1083, 600, 574, 591, 299, 263, 197], [756, 622, 1118, 1130, 132, 1065, 756, 885, 1043, 1130, 499, 1065, 756, 622, 921, 407, 499, 1065, 1067, 741, 1070, 325, 794, 1118, 73, 574, 374], [1123, 591, 172, 457], [756, 731, 606, 264, 53, 248, 1042, 895, 930, 337, 785, 851, 1170], [73, 574, 638, 1183, 299, 1204, 1130, 867, 794, 198, 797, 82, 316, 515, 797, 690, 1101, 371, 299, 906, 736, 645, 499, 1003, 1065, 284, 797, 968, 567, 519], [797, 132, 1057, 93, 43, 998, 421, 600, 558, 510, 299, 37, 716, 43, 167, 1027, 558, 642, 299, 937, 948, 288, 978, 379, 6, 558, 642, 299], [326, 756, 82, 892, 824, 794, 778, 70, 496, 756, 1044, 371, 981, 178, 268, 371, 1081, 181, 545, 206, 756, 572, 930, 794, 945, 29, 574, 741, 1136, 634], [302, 98, 574, 198, 1143, 1094, 772, 870, 264, 550, 1037, 214, 456, 283, 906, 198, 797, 258, 299, 1139, 43, 1123, 1145, 127, 574, 625, 794, 826, 293, 930, 407, 1092], [794, 1101, 797, 740, 628, 510, 163, 1065, 278, 797, 219, 45, 299, 497, 219, 774, 574, 189, 797, 284, 736, 911, 872, 574, 1189, 821, 758, 6, 1154, 167, 957, 163, 797, 371, 358, 325, 1188, 574, 163, 496, 1006, 52], [326, 225, 654, 603, 594, 501, 776, 299, 1144, 288, 816, 299, 58, 1191, 398, 667, 335, 369, 191, 834, 299, 1191, 864, 288, 564, 28, 1065, 605, 1056, 28, 299, 300, 558, 820, 299, 259, 431, 574, 1191, 426, 1207, 835, 58, 564, 59, 44, 738, 1209, 555, 557, 558, 768, 299], [326, 625, 398, 620, 1144, 259, 501, 198, 774, 175, 756, 58, 390, 885, 326, 138, 288, 218, 992, 299, 1113, 1045, 574, 300, 326, 144, 871, 710, 739, 368, 95, 275, 1143, 198, 95, 756, 58, 506, 478, 175, 108, 288, 963, 610, 591, 398, 1101, 4, 1083, 145, 1195, 299, 1143, 1158, 501, 191, 835, 948, 820, 739, 368, 379, 127, 299, 1143, 95, 44, 738, 58], [810, 1183, 693, 1125, 1138, 95, 394, 191, 1034, 310, 95, 132, 499, 163, 510, 774, 6, 209, 248, 111, 1065, 1175, 116, 1146, 1170, 1124, 1009, 213, 510, 774, 132, 1114, 326, 376, 868, 121, 773, 1176, 621, 1184, 621, 768, 293], [797, 163, 797, 181, 84, 496, 325, 1181, 70, 299, 139, 525, 256, 359, 209, 1101, 313, 77, 574, 313, 77, 163, 797, 181], [1140, 306, 794, 651, 70, 1112, 23, 942, 1170, 756, 23, 165, 575, 1034, 680, 326, 529, 1060, 966, 1034, 1023, 597, 300, 182, 774, 966, 851, 456, 966, 1060, 774, 216, 363, 359, 1083, 529, 774, 757, 966, 300, 989, 774, 442, 840, 317, 410, 664, 904, 325, 100, 678, 797, 371, 279], [1052, 671, 678, 198, 1143, 558, 648, 619, 325, 42, 582, 939, 126, 325, 785, 553], [756, 166, 574, 318, 337, 200, 804, 1212, 756, 906, 274, 310, 1130, 163, 216, 387, 591, 989, 163, 467, 597, 1123, 285, 534, 260, 757, 299, 1045, 574, 54, 206], [654, 687, 478, 165, 558, 275, 299, 3, 288, 591, 731, 1107, 39, 359, 868, 219, 786, 731, 1107, 1159, 783, 1130, 682, 687, 363, 634, 1107, 654, 341, 786, 1130, 299, 687], [794, 794, 785, 553, 670, 245, 1006, 574, 359, 383, 678, 785, 561, 738, 239, 245], [222, 1027, 109, 574, 487], [1170, 1147, 219, 831, 574, 22, 736, 325, 407, 537, 1101, 664, 132], [352, 442, 923, 221, 558, 437, 22, 1159, 630, 191, 63, 591, 933, 574, 92, 134, 96, 1165, 299, 1101, 191, 363, 288, 791, 95, 851, 1172, 299, 44, 1182], [1170, 756, 731, 197, 500], [1212, 797, 371, 345, 574, 775, 574, 794, 259, 77, 165, 198], [575, 785, 553, 625, 1183, 605, 186, 606], [323, 306, 930, 1195, 258, 1092, 868, 52, 1052, 671, 198, 501, 264, 467, 1037, 606], [756, 58, 779, 264, 606, 251, 650, 895, 1159, 1065, 371, 797, 650, 785, 851, 1065, 664, 1159, 797, 219, 1136, 299, 219, 581, 756, 58, 1001, 1026, 1025, 574, 581, 664, 1159, 611, 206, 359], [1140, 293, 103, 191, 216, 197, 70, 963, 558, 1197, 1065, 1083, 288, 42, 582, 379, 629, 591, 299, 544, 591, 731, 275, 36, 288, 44, 1083, 1191, 288, 162, 775, 634, 275, 299, 103, 216, 378, 1060, 299], [22, 1017, 44, 461, 774, 948, 44, 797, 220, 1172, 299, 208], [756, 165, 687, 671, 407, 1043, 299, 204, 741, 365, 338, 574, 1070, 407, 402, 671, 775, 773, 299, 152, 545, 6, 1154, 736, 520, 251, 758, 6, 318, 299, 6, 741, 197, 506, 338]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcYwWpBLCK17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_count = lambda sentence: len(word_tokenize(sentence))\n",
        "longest_sentence = max(corpus, key=word_count)\n",
        "length_long_sentence = len(word_tokenize(longest_sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHohsFIRCkNn",
        "colab_type": "code",
        "outputId": "4e37ac54-1429-4b3a-8e27-8c034c6e6570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\n",
        "print(padded_sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 192  433  671 ...    0    0    0]\n",
            " [1175 1049    4 ...    0    0    0]\n",
            " [1098  625  499 ...    0    0    0]\n",
            " ...\n",
            " [1140  293  103 ...    0    0    0]\n",
            " [  22 1017   44 ...    0    0    0]\n",
            " [ 756  165  687 ...    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB-vtt9nCqFL",
        "colab_type": "text"
      },
      "source": [
        "### **Adding Column *'user_stage'* in the input features *'padded_sentences'***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOge-FdXCm0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_temp=pd.DataFrame(data=padded_sentences[0:,0:], index=[i for i in range(padded_sentences.shape[0])], columns=['f'+str(i) for i in range(padded_sentences.shape[1])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHBejtpoDNB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_temp['f' + str(padded_sentences.shape[1])] = df['user_stage']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce_rLeH7Delg",
        "colab_type": "code",
        "outputId": "cfc631db-d53f-4fa9-b1ec-a12cf678ef00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "df_temp.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f0</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>f38</th>\n",
              "      <th>f39</th>\n",
              "      <th>...</th>\n",
              "      <th>f120</th>\n",
              "      <th>f121</th>\n",
              "      <th>f122</th>\n",
              "      <th>f123</th>\n",
              "      <th>f124</th>\n",
              "      <th>f125</th>\n",
              "      <th>f126</th>\n",
              "      <th>f127</th>\n",
              "      <th>f128</th>\n",
              "      <th>f129</th>\n",
              "      <th>f130</th>\n",
              "      <th>f131</th>\n",
              "      <th>f132</th>\n",
              "      <th>f133</th>\n",
              "      <th>f134</th>\n",
              "      <th>f135</th>\n",
              "      <th>f136</th>\n",
              "      <th>f137</th>\n",
              "      <th>f138</th>\n",
              "      <th>f139</th>\n",
              "      <th>f140</th>\n",
              "      <th>f141</th>\n",
              "      <th>f142</th>\n",
              "      <th>f143</th>\n",
              "      <th>f144</th>\n",
              "      <th>f145</th>\n",
              "      <th>f146</th>\n",
              "      <th>f147</th>\n",
              "      <th>f148</th>\n",
              "      <th>f149</th>\n",
              "      <th>f150</th>\n",
              "      <th>f151</th>\n",
              "      <th>f152</th>\n",
              "      <th>f153</th>\n",
              "      <th>f154</th>\n",
              "      <th>f155</th>\n",
              "      <th>f156</th>\n",
              "      <th>f157</th>\n",
              "      <th>f158</th>\n",
              "      <th>f159</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>192</td>\n",
              "      <td>433</td>\n",
              "      <td>671</td>\n",
              "      <td>646</td>\n",
              "      <td>198</td>\n",
              "      <td>501</td>\n",
              "      <td>267</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>pregnant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1175</td>\n",
              "      <td>1049</td>\n",
              "      <td>4</td>\n",
              "      <td>806</td>\n",
              "      <td>248</td>\n",
              "      <td>871</td>\n",
              "      <td>843</td>\n",
              "      <td>1197</td>\n",
              "      <td>4</td>\n",
              "      <td>877</td>\n",
              "      <td>773</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>mother</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1098</td>\n",
              "      <td>625</td>\n",
              "      <td>499</td>\n",
              "      <td>756</td>\n",
              "      <td>906</td>\n",
              "      <td>822</td>\n",
              "      <td>671</td>\n",
              "      <td>972</td>\n",
              "      <td>264</td>\n",
              "      <td>785</td>\n",
              "      <td>107</td>\n",
              "      <td>456</td>\n",
              "      <td>167</td>\n",
              "      <td>454</td>\n",
              "      <td>58</td>\n",
              "      <td>574</td>\n",
              "      <td>1145</td>\n",
              "      <td>772</td>\n",
              "      <td>870</td>\n",
              "      <td>499</td>\n",
              "      <td>263</td>\n",
              "      <td>177</td>\n",
              "      <td>705</td>\n",
              "      <td>471</td>\n",
              "      <td>574</td>\n",
              "      <td>1039</td>\n",
              "      <td>797</td>\n",
              "      <td>371</td>\n",
              "      <td>345</td>\n",
              "      <td>574</td>\n",
              "      <td>1145</td>\n",
              "      <td>648</td>\n",
              "      <td>499</td>\n",
              "      <td>756</td>\n",
              "      <td>1154</td>\n",
              "      <td>219</td>\n",
              "      <td>736</td>\n",
              "      <td>582</td>\n",
              "      <td>245</td>\n",
              "      <td>175</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>pregnant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>894</td>\n",
              "      <td>729</td>\n",
              "      <td>665</td>\n",
              "      <td>857</td>\n",
              "      <td>703</td>\n",
              "      <td>774</td>\n",
              "      <td>1194</td>\n",
              "      <td>111</td>\n",
              "      <td>1191</td>\n",
              "      <td>614</td>\n",
              "      <td>459</td>\n",
              "      <td>165</td>\n",
              "      <td>757</td>\n",
              "      <td>813</td>\n",
              "      <td>572</td>\n",
              "      <td>46</td>\n",
              "      <td>464</td>\n",
              "      <td>564</td>\n",
              "      <td>1070</td>\n",
              "      <td>614</td>\n",
              "      <td>95</td>\n",
              "      <td>703</td>\n",
              "      <td>459</td>\n",
              "      <td>996</td>\n",
              "      <td>167</td>\n",
              "      <td>167</td>\n",
              "      <td>837</td>\n",
              "      <td>22</td>\n",
              "      <td>986</td>\n",
              "      <td>774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>pregnant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>622</td>\n",
              "      <td>756</td>\n",
              "      <td>84</td>\n",
              "      <td>771</td>\n",
              "      <td>667</td>\n",
              "      <td>387</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>pregnant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 160 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     f0    f1   f2   f3   f4   f5  ...  f154  f155  f156  f157  f158      f159\n",
              "0   192   433  671  646  198  501  ...     0     0     0     0     0  pregnant\n",
              "1  1175  1049    4  806  248  871  ...     0     0     0     0     0    mother\n",
              "2  1098   625  499  756  906  822  ...     0     0     0     0     0  pregnant\n",
              "3   894   729  665  857  703  774  ...     0     0     0     0     0  pregnant\n",
              "4   622   756   84  771  667  387  ...     0     0     0     0     0  pregnant\n",
              "\n",
              "[5 rows x 160 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV_mNDO6DYHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df_temp.iloc[:, :].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POUozjrIDdV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le1 = LabelEncoder()\n",
        "X[:, 159] = le1.fit_transform(X[:, 159])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GQfYQt9Emar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_length_long_sentence = length_long_sentence + 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUGl-1n5D6h4",
        "colab_type": "text"
      },
      "source": [
        "### **Building Model**\n",
        "___\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6lv8QFzD1Kn",
        "colab_type": "code",
        "outputId": "8d1b86d3-413a-4797-e4aa-76c3b3e6d165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_length, 50, input_length=new_length_long_sentence))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(7, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-GTeDWIEDSn",
        "colab_type": "code",
        "outputId": "a4b2f419-efef-4ff1-ca75-44fdb6810bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 160, 50)           60800     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 56007     \n",
            "=================================================================\n",
            "Total params: 116,807\n",
            "Trainable params: 116,807\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBYyb8k2EFR6",
        "colab_type": "code",
        "outputId": "bea4c201-05d8-4130-b4ed-507c4c89bca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X, y, batch_size =  10, nb_epoch = 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 1.9654 - acc: 0.1495\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 0s 431us/step - loss: 1.8424 - acc: 0.3551\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 0s 419us/step - loss: 1.7654 - acc: 0.4206\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 0s 392us/step - loss: 1.6802 - acc: 0.4673\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 0s 431us/step - loss: 1.5801 - acc: 0.5794\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 0s 405us/step - loss: 1.4574 - acc: 0.6542\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 0s 397us/step - loss: 1.3233 - acc: 0.8318\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 0s 427us/step - loss: 1.1644 - acc: 0.8692\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 0s 491us/step - loss: 1.0109 - acc: 0.9065\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 0s 467us/step - loss: 0.8692 - acc: 0.9159\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 0s 442us/step - loss: 0.7270 - acc: 0.9439\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 0s 440us/step - loss: 0.5942 - acc: 0.9533\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 0s 514us/step - loss: 0.4960 - acc: 0.9720\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 0s 456us/step - loss: 0.4051 - acc: 0.9720\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 0s 427us/step - loss: 0.3359 - acc: 0.9813\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 0s 433us/step - loss: 0.2826 - acc: 0.9813\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 0s 484us/step - loss: 0.2343 - acc: 0.9907\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 0s 466us/step - loss: 0.1936 - acc: 0.9813\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 0s 429us/step - loss: 0.1658 - acc: 0.9907\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 0s 501us/step - loss: 0.1392 - acc: 0.9907\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 0s 433us/step - loss: 0.1188 - acc: 1.0000\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 0s 411us/step - loss: 0.1028 - acc: 1.0000\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 0s 454us/step - loss: 0.0901 - acc: 1.0000\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 0s 467us/step - loss: 0.0773 - acc: 1.0000\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 0s 452us/step - loss: 0.0679 - acc: 1.0000\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 0s 487us/step - loss: 0.0609 - acc: 1.0000\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 0s 534us/step - loss: 0.0537 - acc: 1.0000\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 0s 396us/step - loss: 0.0483 - acc: 1.0000\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 0s 458us/step - loss: 0.0435 - acc: 1.0000\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 0s 433us/step - loss: 0.0390 - acc: 1.0000\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 0s 414us/step - loss: 0.0357 - acc: 1.0000\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 0s 397us/step - loss: 0.0325 - acc: 1.0000\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 0s 399us/step - loss: 0.0300 - acc: 1.0000\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 0s 423us/step - loss: 0.0275 - acc: 1.0000\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 0s 419us/step - loss: 0.0254 - acc: 1.0000\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 0s 399us/step - loss: 0.0236 - acc: 1.0000\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 0s 409us/step - loss: 0.0221 - acc: 1.0000\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 0s 379us/step - loss: 0.0205 - acc: 1.0000\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 0s 416us/step - loss: 0.0190 - acc: 1.0000\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 0s 408us/step - loss: 0.0179 - acc: 1.0000\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 0s 412us/step - loss: 0.0168 - acc: 1.0000\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 0s 489us/step - loss: 0.0156 - acc: 1.0000\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 0s 408us/step - loss: 0.0147 - acc: 1.0000\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 0s 407us/step - loss: 0.0140 - acc: 1.0000\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 0s 391us/step - loss: 0.0133 - acc: 1.0000\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 0s 408us/step - loss: 0.0125 - acc: 1.0000\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 0s 391us/step - loss: 0.0119 - acc: 1.0000\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 0s 423us/step - loss: 0.0113 - acc: 1.0000\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 0s 408us/step - loss: 0.0108 - acc: 1.0000\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 0s 427us/step - loss: 0.0103 - acc: 1.0000\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 0s 444us/step - loss: 0.0098 - acc: 1.0000\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 0s 454us/step - loss: 0.0094 - acc: 1.0000\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 0s 388us/step - loss: 0.0090 - acc: 1.0000\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 0s 401us/step - loss: 0.0086 - acc: 1.0000\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 0s 403us/step - loss: 0.0083 - acc: 1.0000\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 0s 390us/step - loss: 0.0079 - acc: 1.0000\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 0s 402us/step - loss: 0.0076 - acc: 1.0000\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 0s 431us/step - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 0s 436us/step - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 0s 461us/step - loss: 0.0068 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 0s 475us/step - loss: 0.0065 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 0s 439us/step - loss: 0.0063 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 0s 415us/step - loss: 0.0061 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 0s 452us/step - loss: 0.0059 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 0s 469us/step - loss: 0.0057 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 0s 482us/step - loss: 0.0055 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 0s 476us/step - loss: 0.0053 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 0s 441us/step - loss: 0.0051 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 0s 471us/step - loss: 0.0050 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 0s 442us/step - loss: 0.0048 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 0s 456us/step - loss: 0.0047 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 0s 462us/step - loss: 0.0045 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 0s 449us/step - loss: 0.0044 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 0s 471us/step - loss: 0.0043 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 0s 453us/step - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 0s 431us/step - loss: 0.0040 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 0s 446us/step - loss: 0.0039 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 0s 466us/step - loss: 0.0038 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 0s 462us/step - loss: 0.0037 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 0s 480us/step - loss: 0.0036 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 0s 412us/step - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 0s 514us/step - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 0s 508us/step - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 0s 441us/step - loss: 0.0032 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 0s 427us/step - loss: 0.0032 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 0s 443us/step - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 0s 456us/step - loss: 0.0030 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 0s 475us/step - loss: 0.0029 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 0s 487us/step - loss: 0.0029 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 0s 451us/step - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 0s 443us/step - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 0s 412us/step - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 0s 404us/step - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 0s 425us/step - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 0s 434us/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 0s 408us/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 0s 468us/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 0s 405us/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 0s 396us/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 0s 425us/step - loss: 0.0022 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6915aefbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZYBcqnUEIt0",
        "colab_type": "code",
        "outputId": "60d810bb-b669-4013-a91a-8dc67cb2e2f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "107/107 [==============================] - 0s 389us/step\n",
            "Accuracy: 100.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg-FTT9XE6LT",
        "colab_type": "text"
      },
      "source": [
        "### **Predicting Results for \"test dataset\"**\n",
        "___\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQxCxTibEuuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Mylo/test.csv\", encoding = 'unicode_escape')\n",
        "df_test = df_test.drop('post_id', axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9vOtkaYFHC7",
        "colab_type": "code",
        "outputId": "94518206-302c-41c8-ccae-d50d76e380c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "corpus_test = df_test.iloc[:,0].values\n",
        "nltk.download('punkt')\n",
        "all_words_test = []\n",
        "for sent in corpus_test:\n",
        "    tokenize_word_test = word_tokenize(sent)\n",
        "    for word_test in tokenize_word_test:\n",
        "        all_words_test.append(word_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZJ19sRVFa0A",
        "colab_type": "code",
        "outputId": "09b2e569-e284-47eb-ad42-39fbf6a7ccbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "embedded_sentences_test = [one_hot(sent, vocab_length) for sent in corpus_test]\n",
        "print(embedded_sentences_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[709, 574, 1183, 794, 1027, 1114], [756, 251, 1154, 736, 70, 1130, 764, 741, 889, 1065, 139, 756, 767, 574, 786, 948, 1158, 442, 387, 837, 697, 737, 134, 1159, 680, 400, 359, 464, 582, 461, 774, 95, 442, 163, 288, 498, 1151, 227, 526, 23, 989, 1078, 3, 621, 574, 40, 461, 774, 948, 688, 359, 288, 582, 461, 774, 797, 371, 279, 198, 564, 288, 852, 558, 510, 93, 998, 191, 442, 44, 1006, 333, 288, 116, 240, 774, 1097, 998, 1078, 574, 498, 213, 294], [326, 756, 906, 219, 1100, 407, 496, 1065, 756, 906, 462, 198, 664, 77, 1065, 284, 797, 200, 870, 756, 1154, 338, 600, 139, 204, 98, 574, 167, 326], [658, 1008, 1050, 937, 930, 703, 860, 165, 198], [313, 837, 262, 797, 767, 574, 43, 1047, 1211, 930, 353, 582, 851, 1192, 289, 154, 864, 116, 804, 99, 59, 253, 876, 341, 717], [216, 884, 156, 4, 390, 1118, 774, 398, 1101, 4, 44, 670, 279, 611, 1083, 502], [1147, 590, 70, 326, 235, 756, 706, 502, 1088, 398, 299, 326, 62, 387], [1140, 625, 946, 6, 1191, 574, 209, 1189, 794, 198, 410, 739, 524, 1130, 627, 794, 181, 833, 6, 12, 574, 572, 930, 652, 1065, 558, 739, 515, 1170, 433, 797, 219, 510, 175, 58, 16], [1140, 131, 1159, 816, 1024, 860, 95, 774, 1045, 398, 940, 428, 558, 1012, 299, 44, 162, 461, 299, 558, 496, 496, 621, 517, 44, 162, 593, 558, 903], [959, 70, 200, 889, 597, 302, 229, 70, 167], [49, 595, 957, 600, 317, 705, 1130, 24, 616, 325, 496, 16, 797, 985, 92, 968, 590, 595, 1100], [145, 294, 73, 705, 337, 299, 172, 867], [1072, 764, 58, 703, 807, 374, 1130, 794, 745, 868, 46, 1210, 582, 313, 998, 868, 678, 148, 1130, 1194, 651, 125, 1117, 54, 454, 336, 574, 1145], [690, 1101, 1010, 480, 611, 1059, 33, 937, 299, 685, 150], [1140, 625, 928, 179, 4, 1159, 398, 1101, 191, 687, 420, 776, 1159, 42, 95, 394, 191, 1191, 111, 687, 173, 1191, 1181, 1181, 191, 786, 874, 1132, 41, 420, 776, 1213, 1045, 654, 204, 198, 379, 768, 558, 275, 774, 363, 574, 1182, 558, 284, 966, 654, 687, 223, 558, 510, 774], [397, 325, 756, 1006, 335, 198, 1031, 93, 1025, 678, 889, 1057, 82, 325, 1051, 433, 1164, 371, 139, 756, 1006, 961, 1088, 95, 405, 433, 260, 977, 797, 371, 1033, 574, 1006, 758, 1031, 868, 339], [239, 245, 574, 1006, 359, 739, 785, 561, 738, 1130, 794, 561, 794, 794, 785, 553, 670, 930, 359, 299, 794, 1101], [1098, 12, 756, 906, 648, 1147, 177, 398, 1101, 191, 384, 933, 697, 1065, 259, 1159, 640, 713, 177, 774, 257, 326, 1039, 288, 741, 1146, 76, 271, 326, 776, 774, 299, 543, 832, 1095, 335, 621, 341, 1154, 542, 1026, 540, 678, 777, 467, 1034, 574, 936, 311, 678, 58], [946, 569, 1052, 671, 198, 1143, 225, 279, 173, 186, 127, 1183, 186], [1120, 693, 73, 650, 958, 1105, 777, 738, 738, 216, 64, 597, 599, 963, 48, 774, 756, 3, 195, 269, 1092, 442, 259, 348, 784, 836, 392, 22, 757, 442, 1159, 64, 379, 1175, 868, 857, 51, 1071, 930, 987, 1105, 257, 1176, 359, 191, 1083, 288, 669, 724, 1050, 365, 496, 716, 643, 127, 1130, 177, 371, 245, 1185, 958, 810], [313, 705, 407, 938, 337, 715, 84, 496], [1170, 756, 996, 767, 736, 196, 1183, 537, 499, 756, 1154, 889, 73, 574, 741, 407, 1165], [946, 6, 768, 1197, 971, 1101, 794, 198, 883, 1147, 506, 748, 611, 393, 797, 371, 129, 278, 797, 759, 165], [1140, 773, 398, 772, 870, 4, 37, 77, 618, 515, 558, 899, 278, 134, 738, 989, 287, 582, 584, 899, 278, 443, 579, 1160, 84, 230, 278, 892, 345, 299, 954, 946, 806, 213, 642, 278, 797, 371, 279], [1098, 398, 198, 4, 926, 1191, 759, 774, 44, 162, 1031, 621, 516, 191, 311], [756, 712, 921, 264, 702, 496, 73, 622, 722, 371], [1052, 671, 678, 198, 501, 225, 949], [1159, 308, 591, 558, 642, 299, 865, 402, 510, 680, 299], [1140, 625, 794, 282, 797, 1130, 550, 77, 868, 433, 410, 980, 457, 652, 946, 583, 27, 115, 325, 320, 722, 797, 371, 98, 930, 279, 36, 139, 284, 936, 115, 325, 722, 299, 399, 797, 499, 60], [54, 190, 653, 574, 984, 1101, 1085], [756, 415, 197, 500, 1101, 794, 1027], [830, 797, 219, 966], [122, 671, 198, 1143, 279, 173, 419, 574, 625, 1183, 773, 162, 1123, 77, 95, 496, 597, 916, 428, 631, 275, 756, 906, 648, 575], [709, 574, 1183, 794, 1027, 1114]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePicGrqKF4UX",
        "colab_type": "code",
        "outputId": "d3a3f502-3f85-4e06-ffd4-586b20825396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "padded_sentences_test = pad_sequences(embedded_sentences_test, length_long_sentence, padding='post')\n",
        "print(padded_sentences_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 709  574 1183 ...    0    0    0]\n",
            " [ 756  251 1154 ...    0    0    0]\n",
            " [ 326  756  906 ...    0    0    0]\n",
            " ...\n",
            " [ 830  797  219 ...    0    0    0]\n",
            " [ 122  671  198 ...    0    0    0]\n",
            " [ 709  574 1183 ...    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gCfuQXSGBNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_temp_test=pd.DataFrame(data=padded_sentences_test[0:,0:], index=[i for i in range(padded_sentences_test.shape[0])], columns=['f'+str(i) for i in range(padded_sentences_test.shape[1])])\n",
        "df_temp_test['f' + str(padded_sentences_test.shape[1])] = df_test['user_stage']\n",
        "X_test = df_temp_test.iloc[:, :].values\n",
        "X_test[:, 159] = le1.fit_transform(X_test[:, 159])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKHPf_t-GmLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_final = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc-q4n7KGwhS",
        "colab_type": "code",
        "outputId": "4c8ab3d6-14fa-4685-a2f9-3431eee43a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y_pred_final"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 3, 3, 4, 2, 6, 1, 2, 2, 6, 3, 6, 3, 6, 3, 2, 0, 5, 0, 3, 6, 6,\n",
              "       2, 2, 2, 6, 0, 6, 4, 6, 6, 6, 0, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zbn1ZNzHKaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_result = labelencoder.inverse_transform(y_pred_final)\n",
        "y_result=pd.DataFrame(data = y_result)\n",
        "# Loading the dataset\n",
        "df1 = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Mylo/test.csv\", encoding = 'unicode_escape')\n",
        "df1['tag'] = y_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHIhSMP4HdDV",
        "colab_type": "code",
        "outputId": "47f0cbb9-95f7-4b01-be4f-14336ce2a3d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>question</th>\n",
              "      <th>user_stage</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>Unable to upload my profile pic</td>\n",
              "      <td>pregnant</td>\n",
              "      <td>MyloSupport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90</td>\n",
              "      <td>I dont have any problm in morning whole day bu...</td>\n",
              "      <td>pregnant</td>\n",
              "      <td>General Pregnancy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94</td>\n",
              "      <td>Hi I am not conformed the pregnancy but I am e...</td>\n",
              "      <td>pregnant</td>\n",
              "      <td>General Pregnancy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>102</td>\n",
              "      <td>Best fresh fruit juice for six months old baby</td>\n",
              "      <td>mother</td>\n",
              "      <td>Gossip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>108</td>\n",
              "      <td>Which storage bag is good to store breast milk...</td>\n",
              "      <td>mother</td>\n",
              "      <td>General Baby</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   post_id  ...                tag\n",
              "0       75  ...        MyloSupport\n",
              "1       90  ...  General Pregnancy\n",
              "2       94  ...  General Pregnancy\n",
              "3      102  ...             Gossip\n",
              "4      108  ...       General Baby\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j4fGSvrHdz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.to_csv(\"jain.shubham102.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzbSxq5kH7US",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}